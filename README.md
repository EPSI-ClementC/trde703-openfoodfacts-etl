# OpenFoodFacts ETL - Datamart Nutrition & QualitÃ©

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![Spark](https://img.shields.io/badge/Apache%20Spark-3.5-orange.svg)](https://spark.apache.org/)
[![MariaDB](https://img.shields.io/badge/MariaDB-11.8-blue.svg)](https://mariadb.org/)

> **Projet TRDE703 - M1**
>
> **Auteurs :** FÃ©licien, Charif, ClÃ©ment | **Date :** 25 janvier 2026
>
> Atelier IntÃ©gration des DonnÃ©es - Big Data ETL avec Apache Spark

---

## Livrables du Projet (pour la correction)

### Repo Git structurÃ©
- **[/docs](docs/)** : Documentation complÃ¨te
  - [README.md](README.md) (ce fichier)
  - [data_dictionary.md](docs/data_dictionary.md) : Dictionnaire de donnÃ©es
  - [architecture.md](docs/architecture.md) : Note d'architecture
  - [quality_rules.md](docs/quality_rules.md) : Cahier de qualitÃ©
  - [schemas/datamart_schema.md](docs/schemas/datamart_schema.md) : SchÃ©mas du datamart
- **[/etl](etl/)** : Code Spark (1485 lignes Python)
  - [download_data.py](etl/download_data.py) : TÃ©lÃ©chargement donnÃ©es
  - [bronze_to_silver.py](etl/bronze_to_silver.py) : Nettoyage & transformation
  - [silver_to_gold.py](etl/silver_to_gold.py) : Chargement MariaDB
  - [quality_checks.py](etl/quality_checks.py) : Rapport qualitÃ©
  - [config.py](etl/config.py) : Configuration centralisÃ©e
- **[/sql](sql/)** : Scripts SQL (251 lignes)
  - [ddl/](sql/ddl/) : CrÃ©ation tables (dimensions, faits, bridge)
  - [dml/](sql/dml/) : Manipulation donnÃ©es
  - [queries/analytics.sql](sql/queries/analytics.sql) : 7 requÃªtes analytiques
  - [queries/results.md](sql/queries/results.md) : RÃ©sultats commentÃ©s
- **[/data](data/)** : DonnÃ©es du projet
  - [sample/openfoodfacts-fr-sample-30000.csv](data/sample/) : Sample 30k produits (73 MB inclus dans Git)

### Pipeline Spark reproductible
- **ExÃ©cution :** `python etl/download_data.py` â†’ `bronze_to_silver.py` â†’ `silver_to_gold.py`
- **Logs qualitÃ© :** [logs/](logs/) et [reports/](reports/) (rapports JSON)
- **Architecture :** Bronze â†’ Silver (Parquet) â†’ Gold (MariaDB)

### Datamart MariaDB (schÃ©ma en Ã©toile)
- **Scripts DDL :** [sql/ddl/](sql/ddl/)
  - [01_create_dimensions.sql](sql/ddl/01_create_dimensions.sql) : 5 dimensions
  - [02_create_facts.sql](sql/ddl/02_create_facts.sql) : 1 table de faits
  - [03_create_bridge.sql](sql/ddl/03_create_bridge.sql) : 1 bridge table
- **Scripts DML :** [sql/dml/truncate_all.sql](sql/dml/truncate_all.sql)
- **ModÃ¨le :** 5 dimensions + 1 fait + 1 bridge (voir [datamart_schema.md](docs/schemas/datamart_schema.md))

### Cahier de qualitÃ©
- **Document :** [docs/quality_rules.md](docs/quality_rules.md)
- **RÃ¨gles :** ComplÃ©tude (71%), UnicitÃ© (100%), Bornes, CohÃ©rence
- **Rapports JSON :** [reports/quality_report_*.json](reports/)
- **MÃ©triques :** 29,999 produits, 4,200 marques, 2,100 catÃ©gories

### RequÃªtes analytiques SQL
- **Fichier :** [sql/queries/analytics.sql](sql/queries/analytics.sql) (7 requÃªtes)
- **RÃ©sultats :** [sql/queries/results.md](sql/queries/results.md) (commentÃ©s)
- **KPI couverts :** Top marques Nutri-Score, Distribution par catÃ©gorie, ComplÃ©tude, Anomalies, Ã‰volution temporelle

### Note d'architecture
- **Document :** [docs/architecture.md](docs/architecture.md)
- **Contenu :** Choix techniques, flux ETL, stratÃ©gie SCD2, optimisations Spark/MariaDB

### BONUS : Containerisation Docker
- **Fichiers :** [Dockerfile](Dockerfile), [docker-compose.yml](docker-compose.yml)
- **Guide :** [DOCKER.md](DOCKER.md) (instructions complÃ¨tes)
- **Avantage :** Tester le projet en 2 commandes, aucune installation requise
- **ReproductibilitÃ©** : Environnement identique garanti (Python 3.9, Spark 3.5, MariaDB 8.0)

---

## DÃ©marrage rapide avec Docker (RECOMMANDÃ‰)

**IMPORTANT : Pour tester le projet, consultez le guide complet [DOCKER.md](DOCKER.md)**

**Tester le projet en 2 commandes sans rien installer !**

### PrÃ©requis
- Docker Desktop ([tÃ©lÃ©charger](https://www.docker.com/products/docker-desktop))
- 4 GB RAM disponible

### Lancement rapide

```bash
# 1. DÃ©marrer l'infrastructure (MariaDB + Spark)
docker-compose up -d

# 2. ExÃ©cuter le pipeline ETL complet
docker exec -it openfoodfacts-etl bash run-pipeline.sh
```

**C'est tout !** Le datamart MariaDB est maintenant populÃ© avec 30k produits. ðŸŽ‰

### VÃ©rification rapide

```bash
# Compter les enregistrements
docker exec -it openfoodfacts-mariadb mariadb -u etl_user -pETL_Pass_2025! openfoodfacts_dw -e "
SELECT 'Produits' as table_name, COUNT(*) FROM dim_product
UNION ALL SELECT 'Marques', COUNT(*) FROM dim_brand
UNION ALL SELECT 'CatÃ©gories', COUNT(*) FROM dim_category
UNION ALL SELECT 'Faits', COUNT(*) FROM fact_nutrition_snapshot;"
```

**Guide complet de test :** Voir [DOCKER.md](DOCKER.md) pour toutes les commandes de validation

---

## Sommaire

- [Contexte](#contexte)
- [Objectifs](#objectifs)
- [Architecture](#architecture)
- [PrÃ©requis](#prÃ©requis)
- [Installation](#installation)
- [Configuration](#configuration)
- [ExÃ©cution du Pipeline](#exÃ©cution-du-pipeline)
- [MÃ©triques de QualitÃ©](#mÃ©triques-de-qualitÃ©)
- [RequÃªtes Analytiques](#requÃªtes-analytiques)
- [Structure du Projet](#structure-du-projet)
- [Documentation](#documentation)
- [Auteurs](#auteurs)

---

## Contexte

Ce projet implÃ©mente une **chaÃ®ne d'intÃ©gration de donnÃ©es complÃ¨te (ETL)** utilisant Apache Spark pour traiter les donnÃ©es massives d'OpenFoodFacts et alimenter un datamart MariaDB orientÃ© analyse nutritionnelle et qualitÃ© des produits alimentaires.

### Source de donnÃ©es
- **OpenFoodFacts** : Base de donnÃ©es collaborative open source de produits alimentaires
- Dataset franÃ§ais : ~500k+ produits
- Format : CSV (sÃ©parateur tabulation)
- Mise Ã  jour : Quotidienne
- URL : https://fr.pro.openfoodfacts.org/data

---

## Objectifs

1. **Collecter** les donnÃ©es OpenFoodFacts (exports CSV complets)
2. **Nettoyer et normaliser** les donnÃ©es (qualitÃ©, dÃ©duplication)
3. **ModÃ©liser** en schÃ©ma en Ã©toile (star schema)
4. **Charger** dans un datamart MariaDB
5. **Analyser** avec des requÃªtes SQL pour des KPI mÃ©tier

### KPI visÃ©s
- RÃ©partition Nutri-Score par catÃ©gorie/marque/pays
- Ã‰volution de la complÃ©tude des nutriments
- Taux d'anomalies nutritionnelles
- Classement des marques par qualitÃ© nutritionnelle
- Top catÃ©gories avec anomalies

---

## Architecture

### Architecture Bronze â†’ Silver â†’ Gold

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenFoodFacts  â”‚  Source externe (CSV ~500k produits)
â”‚   (Bronze)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ download_data.py
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw CSV Data   â”‚  DonnÃ©es brutes (data/sample/)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ bronze_to_silver.py
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Silver Layer   â”‚  Parquet nettoyÃ© + normalisÃ© + qualitÃ©
â”‚   (Parquet)     â”‚  - DÃ©duplication
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Harmonisation unitÃ©s
         â”‚           - MÃ©triques qualitÃ©
         â”‚ silver_to_gold.py
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Gold Layer    â”‚  MariaDB - SchÃ©ma en Ã©toile
â”‚  (Datamart)     â”‚  - 5 dimensions
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - 1 table de faits
                     - 1 bridge table
```

### Technologies utilisÃ©es

- **ETL** : Apache Spark 3.5 (PySpark)
- **Datawarehouse** : MariaDB 8.0
- **Langage** : Python 3.8+
- **Format intermÃ©diaire** : Parquet (Silver layer)
- **Stockage** : SystÃ¨me de fichiers local

---

> **Note pour l'Ã©valuation :**
>
> Les sections ci-dessous dÃ©crivent l'installation complÃ¨te pour dÃ©velopper et exÃ©cuter le projet **manuellement** (sans Docker).
>
> **Pour la correction**, il est recommandÃ© d'utiliser uniquement Docker (voir [DOCKER.md](DOCKER.md)) qui permet de tester le projet en 2 commandes :
> ```bash
> docker-compose up -d
> docker exec -it openfoodfacts-etl bash run-pipeline.sh
> ```

---

## PrÃ©requis

### Logiciels requis

```bash
# Versions minimales
Python >= 3.8
Apache Spark >= 3.5
MariaDB >= 8.0
Java >= 11 (pour Spark)
```

### Ressources matÃ©rielles recommandÃ©es

- **RAM** : 8 GB minimum (16 GB recommandÃ©)
- **CPU** : 4 cores minimum
- **Disque** : 10 GB espace libre (donnÃ©es + Spark)

---

## Installation

### 1. Cloner le projet

```bash
git clone <votre-repo>
cd trde703-openfoodfacts-etl
```

### 2. CrÃ©er un environnement virtuel

```bash
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

**DÃ©pendances principales :**
- `pyspark==3.5.3` : Apache Spark pour Python
- `pymariadb==1.1.0` : Connecteur MariaDB
- `pandas==2.1.4` : Manipulation de donnÃ©es
- `requests==2.31.0` : TÃ©lÃ©chargement HTTP
- `python-dotenv==1.0.0` : Gestion variables d'environnement

### 4. TÃ©lÃ©charger le driver JDBC MariaDB

```bash
# Le driver sera automatiquement tÃ©lÃ©chargÃ© par Spark
# via .config("spark.jars.packages", "mariadb:mariadb-connector-java:8.0.33")
```

---

## Configuration

### 1. CrÃ©er le fichier .env

Copier le fichier `.env` et adapter les paramÃ¨tres :

```bash
# Base de donnÃ©es MariaDB
DB_HOST=localhost
DB_PORT=3306
DB_NAME=openfoodfacts_dw
DB_USER=etl_user
DB_PASSWORD=ETL_Pass_2025!

# Configuration Spark
SPARK_MASTER=local[4]
SPARK_DRIVER_MEMORY=4g
SPARK_EXECUTOR_MEMORY=4g

# OpenFoodFacts
OFF_BASE_URL=https://static.openfoodfacts.org/data
OFF_SAMPLE_SIZE=30000
```

### 2. CrÃ©er la base de donnÃ©es MariaDB

```bash
# Se connecter Ã  MariaDB
mariadb -u root -p

# CrÃ©er la base et l'utilisateur
CREATE DATABASE openfoodfacts_dw CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
CREATE USER 'etl_user'@'localhost' IDENTIFIED BY 'ETL_Pass_2025!';
GRANT ALL PRIVILEGES ON openfoodfacts_dw.* TO 'etl_user'@'localhost';
FLUSH PRIVILEGES;
EXIT;
```

### 3. CrÃ©er les tables (DDL)

```bash
# CrÃ©er les dimensions
mariadb -u etl_user -p openfoodfacts_dw < sql/ddl/01_create_dimensions.sql

# CrÃ©er les tables de faits
mariadb -u etl_user -p openfoodfacts_dw < sql/ddl/02_create_facts.sql

# CrÃ©er la bridge table
mariadb -u etl_user -p openfoodfacts_dw < sql/ddl/03_create_bridge.sql
```

---

## ExÃ©cution du Pipeline

### Pipeline complet (ordre recommandÃ©)

```bash
# 1. TÃ©lÃ©charger les donnÃ©es OpenFoodFacts (~3 min)
python etl/download_data.py

# 2. ETL Bronze â†’ Silver (nettoyage + qualitÃ©) (~5 min)
python etl/bronze_to_silver.py

# 3. ETL Silver â†’ Gold (chargement MariaDB) (~8 min)
python etl/silver_to_gold.py

# 4. GÃ©nÃ©ration du rapport de qualitÃ© (~2 min)
python etl/quality_checks.py
```

### DÃ©tails de chaque Ã©tape

#### Ã‰tape 1 : TÃ©lÃ©chargement des donnÃ©es

```bash
python etl/download_data.py
```

**Actions :**
- TÃ©lÃ©charge le dataset franÃ§ais complet (fr.openfoodfacts.org)
- CrÃ©e un sample de 30k produits pour dÃ©veloppement
- Affiche les statistiques de tÃ©lÃ©chargement

**Sorties :**
- `data/sample/openfoodfacts-fr.csv` (~500k produits)
- `data/sample/openfoodfacts-fr-sample-30000.csv` (30k produits)

#### Ã‰tape 2 : Bronze â†’ Silver (Nettoyage)

```bash
python etl/bronze_to_silver.py
```

**Actions :**
- Lecture du CSV avec schÃ©ma explicite
- Nettoyage des chaÃ®nes (trim, normalisation espaces)
- Harmonisation unitÃ©s (sel/sodium : sel â‰ˆ 2.5 Ã— sodium)
- DÃ©duplication par code-barres (garde le plus rÃ©cent)
- Calcul mÃ©triques de qualitÃ© (complÃ©tude, anomalies)
- Hash MD5 pour SCD2

**Sorties :**
- `data/silver/products/*.parquet` (format Parquet optimisÃ©)
- `logs/quality_report_YYYYMMDD_HHMMSS.json`

**MÃ©triques calculÃ©es :**
- `completeness_score` : Score 0-1 de complÃ©tude
- `nb_nutrients_filled` : Nombre de nutriments renseignÃ©s
- `quality_issues_json` : Liste des anomalies dÃ©tectÃ©es
- `row_hash` : Hash pour dÃ©tecter les changements

#### Ã‰tape 3 : Silver â†’ Gold (Chargement MariaDB)

```bash
python etl/silver_to_gold.py
```

**Actions :**
- Chargement des donnÃ©es Silver (Parquet)
- Population des dimensions :
  - `dim_time` : Dimension temporelle (dates)
  - `dim_brand` : Marques (dÃ©doublonnage normalisÃ©)
  - `dim_category` : CatÃ©gories
  - `dim_country` : Pays
  - `dim_product` : Produits (SCD Type 2 prÃ©parÃ©)
- Population de la table de faits `fact_nutrition_snapshot`
- Ã‰criture en mode append via JDBC

**Sorties :**
- Tables MariaDB peuplÃ©es
- Logs de chargement (nombre de lignes par table)

#### Ã‰tape 4 : Rapport de qualitÃ©

```bash
python etl/quality_checks.py
```

**Actions :**
- Analyse de complÃ©tude par dimension
- VÃ©rification unicitÃ© des codes-barres
- DÃ©tection anomalies nutritionnelles
- Distribution Nutri-Score et NOVA
- GÃ©nÃ©ration rapport JSON complet

**Sorties :**
- `reports/quality_report_YYYYMMDD_HHMMSS.json`

---

## MÃ©triques de QualitÃ©

**RÃ¨gles implÃ©mentÃ©es :**
1. **ComplÃ©tude** : Score 0-1 sur 8 champs critiques (nom, marque, catÃ©gorie, 5 nutriments)
2. **UnicitÃ©** : Un code-barres = un produit (dÃ©duplication par `last_modified_t`)
3. **Bornes** : Nutriments dans intervalles rÃ©alistes (ex: 0-100g pour 100g)
4. **CohÃ©rence** : Harmonisation sel/sodium (sel â‰ˆ 2.5 Ã— sodium)

**RÃ©sultats (sample 30k) :**
- ComplÃ©tude moyenne : **71%** âœ…
- UnicitÃ© : **100%** âœ…
- Anomalies : **4.4%** (2215 produits) âš ï¸
- Distribution Nutri-Score : A:4209, B:2091, C:3365, D:4292, E:5898

---

## RequÃªtes Analytiques

**7 requÃªtes SQL disponibles** dans [`sql/queries/analytics.sql`](sql/queries/analytics.sql) :

1. **Top 10 marques** par Nutri-Score A/B
2. **Distribution Nutri-Score** par catÃ©gorie
3. **Analyse sucres** par catÃ©gorie (moyenne, min, max)
4. **Taux de complÃ©tude** par marque
5. **Liste anomalies** nutritionnelles (sucres > 80g, sel > 25g)
6. **Ã‰volution hebdomadaire** de la complÃ©tude (6 derniers mois)
7. **Top catÃ©gories** avec anomalies

**RÃ©sultats commentÃ©s** disponibles dans `sql/queries/results.md`

---

## Structure du Projet

```
trde703-openfoodfacts-etl/
â”‚
â”œâ”€â”€ README.md                    # Ce fichier
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python
â”œâ”€â”€ .env                         # Configuration (Ã  crÃ©er)
â”œâ”€â”€ .gitignore                   # Fichiers ignorÃ©s par Git
â”‚
â”œâ”€â”€ data/                        # DonnÃ©es (gitignored)
â”‚   â”œâ”€â”€ sample/                  # CSV tÃ©lÃ©chargÃ©s
â”‚   â”‚   â”œâ”€â”€ openfoodfacts-fr.csv
â”‚   â”‚   â””â”€â”€ openfoodfacts-fr-sample-30000.csv
â”‚   â””â”€â”€ silver/                  # Parquet nettoyÃ©
â”‚       â””â”€â”€ products/*.parquet
â”‚
â”œâ”€â”€ etl/                         # Code ETL Spark
â”‚   â”œâ”€â”€ config.py                # Configuration centralisÃ©e
â”‚   â”œâ”€â”€ download_data.py         # TÃ©lÃ©chargement OpenFoodFacts
â”‚   â”œâ”€â”€ bronze_to_silver.py      # Nettoyage + normalisation
â”‚   â”œâ”€â”€ silver_to_gold.py        # Chargement MariaDB
â”‚   â”œâ”€â”€ quality_checks.py        # GÃ©nÃ©ration rapport qualitÃ©
â”‚   â”œâ”€â”€ explore_schema.py        # Exploration du schÃ©ma CSV
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ quality.py           # Fonctions de qualitÃ©
â”‚
â”œâ”€â”€ sql/                         # Scripts SQL
â”‚   â”œâ”€â”€ ddl/                     # Data Definition Language
â”‚   â”‚   â”œâ”€â”€ 01_create_dimensions.sql
â”‚   â”‚   â”œâ”€â”€ 02_create_facts.sql
â”‚   â”‚   â””â”€â”€ 03_create_bridge.sql
â”‚   â”œâ”€â”€ dml/                     # Data Manipulation Language
â”‚   â”‚   â””â”€â”€ truncate_all.sql
â”‚   â””â”€â”€ queries/                 # RequÃªtes analytiques
â”‚       â””â”€â”€ analytics.sql
â”‚
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ architecture.md          # Note d'architecture
â”‚   â”œâ”€â”€ data_dictionary.md       # Dictionnaire de donnÃ©es
â”‚   â”œâ”€â”€ quality_rules.md         # RÃ¨gles de qualitÃ© dÃ©taillÃ©es
â”‚   â””â”€â”€ schemas/                 # SchÃ©mas et diagrammes
â”‚       â””â”€â”€ datamart_schema.md
â”‚
â”œâ”€â”€ logs/                        # Logs ETL (gitignored)
â”‚   â””â”€â”€ quality_report_*.json
â”‚
â””â”€â”€ reports/                     # Rapports de qualitÃ© (gitignored)
    â””â”€â”€ quality_report_*.json
```

---

## Documentation

### Documents disponibles

- **[Architecture](docs/architecture.md)** : Choix techniques, flux de donnÃ©es, stratÃ©gies
- **[Data Dictionary](docs/data_dictionary.md)** : SchÃ©ma complet du datamart
- **[Quality Rules](docs/quality_rules.md)** : RÃ¨gles de qualitÃ© dÃ©taillÃ©es avec exemples
- **[Datamart Schema](docs/schemas/datamart_schema.md)** : Diagramme ER et explications

### SchÃ©ma du datamart (rÃ©sumÃ©)

**Dimensions :**
- `dim_time` (time_sk) : Dimension temporelle
- `dim_brand` (brand_sk) : Marques
- `dim_category` (category_sk) : CatÃ©gories (hiÃ©rarchique)
- `dim_country` (country_sk) : Pays
- `dim_product` (product_sk) : Produits (SCD Type 2)

**Faits :**
- `fact_nutrition_snapshot` : Mesures nutritionnelles + scores

**Bridge :**
- `bridge_product_category` : Relation N-N produits â†” catÃ©gories

---

## Auteurs

**Projet rÃ©alisÃ© par :**
- FÃ©licien
- Charif
- ClÃ©ment

**Date :** 25 janvier 2026